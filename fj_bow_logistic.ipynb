{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fj_bow_logistic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONDj1+J7LdK47KkDSmqSsa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-dube/fakejobs/blob/main/fj_bow_logistic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFWTUL3GCHsG"
      },
      "source": [
        "# Load the modules used\n",
        "import numpy as np\n",
        "import scipy as sci\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55AqcsYyb-aa"
      },
      "source": [
        "# For reproducible results\n",
        "# except for variability introduced by GPU\n",
        "import random as rn\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = '42'\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # avoid using GPU for reproducible results\n",
        "np.random.seed(42)\n",
        "rn.seed(42)\n",
        "# tf.random.set_seed(42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrnTamUHDzxI"
      },
      "source": [
        "# Set data_url, the location of the data\n",
        "# Data is not loaded from a local file\n",
        "# data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fj_small.csv\"\n",
        "# data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fj_medium.csv\"\n",
        "data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fake_job_postings.csv\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usYPD_l1Bimz"
      },
      "source": [
        "def fj_load_df_from_url():\n",
        "    \"\"\"\n",
        "    Load dataframe from csv file\n",
        "    Input:\n",
        "        None\n",
        "    Returns:\n",
        "        dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(data_url)\n",
        "\n",
        "    print ('Loaded dataframe shape', df.shape)\n",
        "\n",
        "    counts = fj_label_stats(df)\n",
        "    print ('Not fraudulent', counts[0], 'Fraudulent', counts[1])\n",
        "\n",
        "    print(df.describe())\n",
        "\n",
        "    print ('NAs/NANs in data =>')\n",
        "    print(df.isna().sum())\n",
        "\n",
        "    return df\n",
        "\n",
        "def fj_label_stats(df):\n",
        "    \"\"\"\n",
        "    Very basic label statistics\n",
        "    Input: \n",
        "        Dataframe\n",
        "    Returns:\n",
        "        Number of samples with 0, 1 as the label\n",
        "    \"\"\"\n",
        "    counts = np.bincount(df['fraudulent'])\n",
        "    return counts\n",
        "\n",
        "def fj_txt_only(df):\n",
        "    \"\"\"\n",
        "    Combine all the text fields, discard everything else except for the label\n",
        "    Input: \n",
        "        Dataframe\n",
        "    Returns:\n",
        "        Processed dataframe\n",
        "    \"\"\"\n",
        "    \n",
        "    df.fillna(\" \", inplace = True)\n",
        "\n",
        "    df['text'] = df['title'] + ' ' + df['location'] + ' ' + df['department'] + \\\n",
        "    ' ' + df['company_profile'] + ' ' + df['description'] + ' ' + \\\n",
        "    df['requirements'] + ' ' + df['benefits'] + ' ' + df['employment_type'] + \\\n",
        "    ' ' + df['required_education'] + ' ' + df['industry'] + ' ' + df['function'] \n",
        "\n",
        "    del df['title']\n",
        "    del df['location']\n",
        "    del df['department']\n",
        "    del df['company_profile']\n",
        "    del df['description']\n",
        "    del df['requirements']\n",
        "    del df['benefits']\n",
        "    del df['employment_type']\n",
        "    del df['required_experience']\n",
        "    del df['required_education']\n",
        "    del df['industry']\n",
        "    del df['function']  \n",
        "    \n",
        "    del df['salary_range']\n",
        "    del df['job_id']\n",
        "    del df['telecommuting']\n",
        "    del df['has_company_logo']\n",
        "    del df['has_questions']\n",
        "\n",
        "    return df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lks9Mm0Tc1l2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1457b44b-2638-4b96-c3ed-ecd13c9ef60e"
      },
      "source": [
        "df = fj_load_df_from_url()\n",
        "df = fj_txt_only(df)\n",
        "print('Maximum text length', df['text'].str.len().max())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded dataframe shape (17880, 18)\n",
            "Not fraudulent 17014 Fraudulent 866\n",
            "             job_id  telecommuting  ...  has_questions    fraudulent\n",
            "count  17880.000000   17880.000000  ...   17880.000000  17880.000000\n",
            "mean    8940.500000       0.042897  ...       0.491723      0.048434\n",
            "std     5161.655742       0.202631  ...       0.499945      0.214688\n",
            "min        1.000000       0.000000  ...       0.000000      0.000000\n",
            "25%     4470.750000       0.000000  ...       0.000000      0.000000\n",
            "50%     8940.500000       0.000000  ...       0.000000      0.000000\n",
            "75%    13410.250000       0.000000  ...       1.000000      0.000000\n",
            "max    17880.000000       1.000000  ...       1.000000      1.000000\n",
            "\n",
            "[8 rows x 5 columns]\n",
            "NAs/NANs in data =>\n",
            "job_id                     0\n",
            "title                      0\n",
            "location                 346\n",
            "department             11547\n",
            "salary_range           15012\n",
            "company_profile         3308\n",
            "description                1\n",
            "requirements            2695\n",
            "benefits                7210\n",
            "telecommuting              0\n",
            "has_company_logo           0\n",
            "has_questions              0\n",
            "employment_type         3471\n",
            "required_experience     7050\n",
            "required_education      8105\n",
            "industry                4903\n",
            "function                6455\n",
            "fraudulent                 0\n",
            "dtype: int64\n",
            "Maximum text length 14991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du7VqtSUsaA1"
      },
      "source": [
        "# train-test split\n",
        "train_text, test_text, train_labels , test_labels = train_test_split(df['text'], df['fraudulent'] , test_size = 0.15)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJIwNfj9XR_p"
      },
      "source": [
        "# model 1: BOW + logistic model\n",
        "# dense representation is not imposed by logistic regression\n",
        "# sparse representation is needed so that logistic regression does not run out of memory\n",
        "cv = CountVectorizer(strip_accents='unicode', lowercase=True, stop_words='english', dtype=np.int8) \n",
        "cv_train_sparse = cv.fit_transform(train_text)\n",
        "# cv_train_dense = sci.sparse.csr_matrix.todense(cv_train_sparse)\n",
        "\n",
        "cv_test_sparse = cv.transform(test_text)\n",
        "# cv_test_dense = sci.sparse.csr_matrix.todense(cv_test_sparse)\n",
        "# print('BOW for cv_train:', cv_train_dense.shape)\n",
        "# print('BOW for cv_test:', cv_test_dense.shape)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB9bhVRCFot1",
        "outputId": "ea062f07-cdb8-46d3-e153-26e733e3c6a0"
      },
      "source": [
        "type(cv_test_sparse)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--t8kVV5XlBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff768e4-e68c-4711-c77f-5a09a435caff"
      },
      "source": [
        "MAX_ITER = 100\n",
        "model1 = LogisticRegression(max_iter=MAX_ITER)\n",
        "model1.fit(cv_train_sparse, train_labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erun5IhWsv2d"
      },
      "source": [
        "pred_soft1 = model1.predict(cv_test_sparse)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLIwh073XpxW",
        "outputId": "c2aab9e3-fa50-4579-ea9c-a3bf8044aa41"
      },
      "source": [
        "# pred = np.around(pred_soft, decimals = 0)\n",
        "pred1 = np.where(pred_soft1 > 0.15, 1, 0)\n",
        "\n",
        "acc1 = accuracy_score(pred1, test_labels)\n",
        "f11 = f1_score(pred1, test_labels)\n",
        "\n",
        "cm1 = confusion_matrix(test_labels, pred1)\n",
        "tn1 = cm1[0][0]\n",
        "fn1 = cm1[1][0]\n",
        "tp1 = cm1[1][1]\n",
        "fp1 = cm1[0][1]\n",
        "\n",
        "print('Accuracy score: {:.4f}'.format(acc1), 'F1 score: {:.4f}'.format(f11))\n",
        "print('False Positives: {:.0f}'.format(fp1), 'False Negatives: {:.0f}'.format(fn1))\n",
        "print('Confusion matrix:\\n', cm1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.9858 F1 score: 0.8538\n",
            "False Positives: 5 False Negatives: 33\n",
            "Confusion matrix:\n",
            " [[2533    5]\n",
            " [  33  111]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67DednbZG6Hb",
        "outputId": "0278963d-3323-4830-83c0-672dfadefedd"
      },
      "source": [
        "# sanity check the model parameters\n",
        "print (type(model1.coef_), model1.coef_.shape[0], model1.coef_.shape[1])\n",
        "print (model1.coef_, model1.intercept_)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> 1 96150\n",
            "[[-9.65592381e-02  5.02190765e-01 -9.68099635e-03 ... -1.04612747e-06\n",
            "  -1.04612747e-06 -1.04612747e-06]] [-1.58213478]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr3hwxbwI1mT",
        "outputId": "eb05b602-7eaf-48b0-d7d1-6d295f072a62"
      },
      "source": [
        "# print the top-k words with the largest coefficients\n",
        "# these words contribute the most to a job description declared fraudulent\n",
        "coef = model1.coef_.reshape(model1.coef_.shape[1])\n",
        "k = 20\n",
        "ind = np.argpartition(coef, -k)[-k:]\n",
        "for i in range (k):\n",
        "  print(ind[i], coef[ind[i]], list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(ind[i])])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33685 0.583666549778054 forward\n",
            "90601 0.5880771388570726 warsaw\n",
            "50275 0.5922453583229651 migration\n",
            "58424 0.5894725690060855 personable\n",
            "25611 0.6014009057248951 duration\n",
            "3537 0.6200141194192783 administrative\n",
            "85478 0.6097342380566507 trends\n",
            "2560 0.6230277267508464 accountant\n",
            "51410 0.6342872633589646 motivated\n",
            "51049 0.6430812625819265 money\n",
            "8060 0.6540206821739426 au\n",
            "25832 0.7034693991546753 earn\n",
            "2420 0.7909873621854235 accion\n",
            "28288 0.7036004048677369 entry\n",
            "90433 0.696350398561821 wages\n",
            "70901 1.2517113334375831 rohan\n",
            "6562 0.8661454561535944 aptitude\n",
            "53381 0.6744264060592281 northwestern\n",
            "45978 1.0131995590683975 link\n",
            "4869 0.6697178300384368 american\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}