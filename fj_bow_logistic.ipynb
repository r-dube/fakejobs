{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fj_bow_logistic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvrZEkrnv7WpyjKZ6sFrJe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-dube/fakejobs/blob/main/fj_bow_logistic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFWTUL3GCHsG"
      },
      "source": [
        "# Load the modules used\n",
        "import numpy as np\n",
        "import scipy as sci\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55AqcsYyb-aa"
      },
      "source": [
        "# For reproducible results\n",
        "# except for variability introduced by GPU\n",
        "import random as rn\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = '42'\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1' # avoid using GPU for reproducible results\n",
        "np.random.seed(42)\n",
        "rn.seed(42)\n",
        "# tf.random.set_seed(42)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrnTamUHDzxI"
      },
      "source": [
        "# Set data_url, the location of the data\n",
        "# Data is not loaded from a local file\n",
        "# data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fj_small.csv\"\n",
        "# data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fj_medium.csv\"\n",
        "data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fake_job_postings.csv\""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usYPD_l1Bimz"
      },
      "source": [
        "def fj_load_df_from_url():\n",
        "    \"\"\"\n",
        "    Load dataframe from csv file\n",
        "    Input:\n",
        "        None\n",
        "    Returns:\n",
        "        dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(data_url)\n",
        "\n",
        "    print ('Loaded dataframe shape', df.shape)\n",
        "\n",
        "    counts = fj_label_stats(df)\n",
        "    print ('Not fraudulent', counts[0], 'Fraudulent', counts[1])\n",
        "\n",
        "    print(df.describe())\n",
        "\n",
        "    print ('NAs/NANs in data =>')\n",
        "    print(df.isna().sum())\n",
        "\n",
        "    return df\n",
        "\n",
        "def fj_label_stats(df):\n",
        "    \"\"\"\n",
        "    Very basic label statistics\n",
        "    Input: \n",
        "        Dataframe\n",
        "    Returns:\n",
        "        Number of samples with 0, 1 as the label\n",
        "    \"\"\"\n",
        "    counts = np.bincount(df['fraudulent'])\n",
        "    return counts\n",
        "\n",
        "def fj_txt_only(df):\n",
        "    \"\"\"\n",
        "    Combine all the text fields, discard everything else except for the label\n",
        "    Input: \n",
        "        Dataframe\n",
        "    Returns:\n",
        "        Processed dataframe\n",
        "    \"\"\"\n",
        "    \n",
        "    df.fillna(\" \", inplace = True)\n",
        "\n",
        "    df['text'] = df['title'] + ' ' + df['location'] + ' ' + df['department'] + \\\n",
        "    ' ' + df['company_profile'] + ' ' + df['description'] + ' ' + \\\n",
        "    df['requirements'] + ' ' + df['benefits'] + ' ' + df['employment_type'] + \\\n",
        "    ' ' + df['required_education'] + ' ' + df['industry'] + ' ' + df['function'] \n",
        "\n",
        "    del df['title']\n",
        "    del df['location']\n",
        "    del df['department']\n",
        "    del df['company_profile']\n",
        "    del df['description']\n",
        "    del df['requirements']\n",
        "    del df['benefits']\n",
        "    del df['employment_type']\n",
        "    del df['required_experience']\n",
        "    del df['required_education']\n",
        "    del df['industry']\n",
        "    del df['function']  \n",
        "    \n",
        "    del df['salary_range']\n",
        "    del df['job_id']\n",
        "    del df['telecommuting']\n",
        "    del df['has_company_logo']\n",
        "    del df['has_questions']\n",
        "\n",
        "    return df"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lks9Mm0Tc1l2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78203f71-3f96-4a82-a43e-79cbc31a04be"
      },
      "source": [
        "df = fj_load_df_from_url()\n",
        "df = fj_txt_only(df)\n",
        "print('Maximum text length', df['text'].str.len().max())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded dataframe shape (17880, 18)\n",
            "Not fraudulent 17014 Fraudulent 866\n",
            "             job_id  telecommuting  ...  has_questions    fraudulent\n",
            "count  17880.000000   17880.000000  ...   17880.000000  17880.000000\n",
            "mean    8940.500000       0.042897  ...       0.491723      0.048434\n",
            "std     5161.655742       0.202631  ...       0.499945      0.214688\n",
            "min        1.000000       0.000000  ...       0.000000      0.000000\n",
            "25%     4470.750000       0.000000  ...       0.000000      0.000000\n",
            "50%     8940.500000       0.000000  ...       0.000000      0.000000\n",
            "75%    13410.250000       0.000000  ...       1.000000      0.000000\n",
            "max    17880.000000       1.000000  ...       1.000000      1.000000\n",
            "\n",
            "[8 rows x 5 columns]\n",
            "NAs/NANs in data =>\n",
            "job_id                     0\n",
            "title                      0\n",
            "location                 346\n",
            "department             11547\n",
            "salary_range           15012\n",
            "company_profile         3308\n",
            "description                1\n",
            "requirements            2695\n",
            "benefits                7210\n",
            "telecommuting              0\n",
            "has_company_logo           0\n",
            "has_questions              0\n",
            "employment_type         3471\n",
            "required_experience     7050\n",
            "required_education      8105\n",
            "industry                4903\n",
            "function                6455\n",
            "fraudulent                 0\n",
            "dtype: int64\n",
            "Maximum text length 14991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du7VqtSUsaA1"
      },
      "source": [
        "# train-test split\n",
        "train_text, test_text, train_labels , test_labels = train_test_split(df['text'], df['fraudulent'] , test_size = 0.15)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJIwNfj9XR_p"
      },
      "source": [
        "# model 1: BOW + logistic model\n",
        "# dense representation is not imposed by logistic regression\n",
        "# sparse representation is needed so that logistic regression does not run out of memory\n",
        "cv = CountVectorizer(strip_accents='unicode', lowercase=True, stop_words='english', dtype=np.int8, binary=True) \n",
        "cv_train_sparse = cv.fit_transform(train_text)\n",
        "# cv_train_dense = sci.sparse.csr_matrix.todense(cv_train_sparse)\n",
        "\n",
        "cv_test_sparse = cv.transform(test_text)\n",
        "# cv_test_dense = sci.sparse.csr_matrix.todense(cv_test_sparse)\n",
        "# print('BOW for cv_train:', cv_train_dense.shape)\n",
        "# print('BOW for cv_test:', cv_test_dense.shape)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB9bhVRCFot1",
        "outputId": "d52a197c-fe7d-4065-eb78-645aa22cd7fb"
      },
      "source": [
        "type(cv_test_sparse)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--t8kVV5XlBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4fc44fa-0e20-4caa-afcb-d4ff1cb8d99a"
      },
      "source": [
        "MAX_ITER = 100\n",
        "model1 = LogisticRegression(max_iter=MAX_ITER)\n",
        "model1.fit(cv_train_sparse, train_labels)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erun5IhWsv2d"
      },
      "source": [
        "lr_probs = model1.predict_proba(cv_test_sparse)\n",
        "pred_soft1 = lr_probs[:, 1]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZer4TvZgh4o",
        "outputId": "dba6d3c3-d1f3-45de-8067-18022e4cca8e"
      },
      "source": [
        "print(pred_soft1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.22816095e-05 3.75057717e-03 4.88709043e-05 ... 6.81889461e-04\n",
            " 3.76782525e-05 2.59394883e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLIwh073XpxW",
        "outputId": "81488447-9f22-42db-a6b6-503937699f55"
      },
      "source": [
        "# pred = np.around(pred_soft, decimals = 0)\n",
        "pred1 = np.where(pred_soft1 > 0.15, 1, 0)\n",
        "\n",
        "acc1 = accuracy_score(pred1, test_labels)\n",
        "f11 = f1_score(pred1, test_labels)\n",
        "\n",
        "cm1 = confusion_matrix(test_labels, pred1)\n",
        "tn1 = cm1[0][0]\n",
        "fn1 = cm1[1][0]\n",
        "tp1 = cm1[1][1]\n",
        "fp1 = cm1[0][1]\n",
        "\n",
        "print('Accuracy score: {:.4f}'.format(acc1), 'F1 score: {:.4f}'.format(f11))\n",
        "print('False Positives: {:.0f}'.format(fp1), 'False Negatives: {:.0f}'.format(fn1))\n",
        "print('Confusion matrix:\\n', cm1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.9858 F1 score: 0.8652\n",
            "False Positives: 16 False Negatives: 22\n",
            "Confusion matrix:\n",
            " [[2522   16]\n",
            " [  22  122]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67DednbZG6Hb",
        "outputId": "c2ee630b-464c-4877-aaf9-b42e0f82bc22"
      },
      "source": [
        "# sanity check the model parameters\n",
        "print (type(model1.coef_), model1.coef_.shape[0], model1.coef_.shape[1])\n",
        "print (model1.coef_, model1.intercept_)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> 1 96150\n",
            "[[-2.98880470e-01  7.79473753e-01 -6.27442703e-03 ... -1.83999169e-05\n",
            "  -1.83999169e-05 -1.83999169e-05]] [-1.55240758]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr3hwxbwI1mT",
        "outputId": "f776eb27-1faa-4cdd-d978-134c9f76d2aa"
      },
      "source": [
        "# print the top-k words with the largest coefficients\n",
        "# these words contribute the most to a job description declared fraudulent\n",
        "coef = model1.coef_.reshape(model1.coef_.shape[1])\n",
        "k = 20\n",
        "ind = np.argpartition(coef, -k)[-k:]\n",
        "for i in range (k):\n",
        "  print(ind[i], coef[ind[i]], list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(ind[i])])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8876 0.6258794722749936 balance\n",
            "73348 0.6333128423457315 send\n",
            "25611 0.6259285387198736 duration\n",
            "38004 0.6434919556502703 hospital\n",
            "90433 0.75822867725062 wages\n",
            "51049 0.7556025983045982 money\n",
            "54480 0.7290765727550464 oil\n",
            "26515 0.7340161687538614 egovernment\n",
            "939 0.6560803983381377 28\n",
            "6562 0.7140744759683485 aptitude\n",
            "90601 0.6543170280066289 warsaw\n",
            "54398 0.7694429585002532 offshore\n",
            "2587 1.0494498113942459 accounting\n",
            "83983 0.8756074645931318 timejob\n",
            "1 0.7794737530953701 000\n",
            "45978 1.4066493742729074 link\n",
            "70901 1.2020262877494345 rohan\n",
            "3537 0.9737890429754346 administrative\n",
            "8060 0.8073265859315331 au\n",
            "25832 1.0480087026327678 earn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhM7IbDJe_w7",
        "outputId": "3588e7b7-1ddf-4c26-9fd5-9c18acb28637"
      },
      "source": [
        "\"\"\"\n",
        "# Uncomment to save results on drive to a csv file\n",
        "df_results1 = pd.DataFrame(data=test_labels)\n",
        "df_results1.reset_index(drop=True, inplace=True)\n",
        "df_results2 = pd.DataFrame(data=pred_soft1, columns=['logistic'])\n",
        "df_results = pd.concat([df_results1, df_results2], axis=1)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "results_file='/content/drive/My Drive/Results/logistic.csv'\n",
        "\n",
        "df_results.to_csv(results_file)\n",
        "\"\"\""
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}