{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fj_char_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPT8Y+pCjBMIDCFZgQTmNH9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-dube/fakejobs/blob/main/fj_char_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFWTUL3GCHsG"
      },
      "source": [
        "# Load the modules used\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, GlobalMaxPool1D, Conv1D, MaxPool1D, Flatten\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.initializers import Constant \n",
        "from keras.optimizers import Adam\n",
        "from keras import metrics\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from collections import Counter"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA2hoxGqDO6t"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK7zNIN2x-DP",
        "outputId": "85f1a978-57c2-4ed6-e32f-d11b33537026"
      },
      "source": [
        "# NLTK to remove stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wN7spE3GCrZ"
      },
      "source": [
        "# For reproducible results\n",
        "import random as rn\n",
        "import os\n",
        "import tensorflow as tf\n",
        "os.environ['PYTHONHASHSEED'] = '42'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
        "np.random.seed(42)\n",
        "rn.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrnTamUHDzxI"
      },
      "source": [
        "# Set data_url, the location of the data\n",
        "# Data is not loaded from a local file\n",
        "# data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fj_small.csv\"\n",
        "# data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fj_medium.csv\"\n",
        "data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fake_job_postings.csv\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usYPD_l1Bimz"
      },
      "source": [
        "def fj_load_df_from_url():\n",
        "    \"\"\"\n",
        "    Load dataframe from csv file\n",
        "    Input:\n",
        "        None\n",
        "    Returns:\n",
        "        dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(data_url)\n",
        "\n",
        "    print ('Loaded dataframe shape', df.shape)\n",
        "\n",
        "    counts = fj_label_stats(df)\n",
        "    print ('Not fraudulent', counts[0], 'Fraudulent', counts[1])\n",
        "\n",
        "    print(df.describe())\n",
        "\n",
        "    print ('NAs/NANs in data =>')\n",
        "    print(df.isna().sum())\n",
        "\n",
        "    return df\n",
        "\n",
        "def fj_label_stats(df):\n",
        "    \"\"\"\n",
        "    Very basic label statistics\n",
        "    Input: \n",
        "        Dataframe\n",
        "    Returns:\n",
        "        Number of samples with 0, 1 as the label\n",
        "    \"\"\"\n",
        "    counts = np.bincount(df['fraudulent'])\n",
        "    return counts\n",
        "\n",
        "def fj_txt_only(df):\n",
        "    \"\"\"\n",
        "    Combine all the text fields, discard everything else except for the label\n",
        "    Input: \n",
        "        Dataframe\n",
        "    Returns:\n",
        "        Processed dataframe\n",
        "    \"\"\"\n",
        "    \n",
        "    df.fillna(\" \", inplace = True)\n",
        "\n",
        "    df['text'] = df['title'] + ' ' + df['location'] + ' ' + df['department'] + \\\n",
        "    ' ' + df['company_profile'] + ' ' + df['description'] + ' ' + \\\n",
        "    df['requirements'] + ' ' + df['benefits'] + ' ' + df['employment_type'] + \\\n",
        "    ' ' + df['required_education'] + ' ' + df['industry'] + ' ' + df['function'] \n",
        "\n",
        "    del df['title']\n",
        "    del df['location']\n",
        "    del df['department']\n",
        "    del df['company_profile']\n",
        "    del df['description']\n",
        "    del df['requirements']\n",
        "    del df['benefits']\n",
        "    del df['employment_type']\n",
        "    del df['required_experience']\n",
        "    del df['required_education']\n",
        "    del df['industry']\n",
        "    del df['function']  \n",
        "    \n",
        "    del df['salary_range']\n",
        "    del df['job_id']\n",
        "    del df['telecommuting']\n",
        "    del df['has_company_logo']\n",
        "    del df['has_questions']\n",
        "\n",
        "    return df"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lks9Mm0Tc1l2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48fa819-f722-4d51-e063-4c378d296b92"
      },
      "source": [
        "df = fj_load_df_from_url()\n",
        "df = fj_txt_only(df)\n",
        "print('Maximum text length', df['text'].str.len().max())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded dataframe shape (17880, 18)\n",
            "Not fraudulent 17014 Fraudulent 866\n",
            "             job_id  telecommuting  ...  has_questions    fraudulent\n",
            "count  17880.000000   17880.000000  ...   17880.000000  17880.000000\n",
            "mean    8940.500000       0.042897  ...       0.491723      0.048434\n",
            "std     5161.655742       0.202631  ...       0.499945      0.214688\n",
            "min        1.000000       0.000000  ...       0.000000      0.000000\n",
            "25%     4470.750000       0.000000  ...       0.000000      0.000000\n",
            "50%     8940.500000       0.000000  ...       0.000000      0.000000\n",
            "75%    13410.250000       0.000000  ...       1.000000      0.000000\n",
            "max    17880.000000       1.000000  ...       1.000000      1.000000\n",
            "\n",
            "[8 rows x 5 columns]\n",
            "NAs/NANs in data =>\n",
            "job_id                     0\n",
            "title                      0\n",
            "location                 346\n",
            "department             11547\n",
            "salary_range           15012\n",
            "company_profile         3308\n",
            "description                1\n",
            "requirements            2695\n",
            "benefits                7210\n",
            "telecommuting              0\n",
            "has_company_logo           0\n",
            "has_questions              0\n",
            "employment_type         3471\n",
            "required_experience     7050\n",
            "required_education      8105\n",
            "industry                4903\n",
            "function                6455\n",
            "fraudulent                 0\n",
            "dtype: int64\n",
            "Maximum text length 14991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxtcnlHBpPro"
      },
      "source": [
        "# Utilities to clean text\n",
        "\n",
        "def remove_URL(text):\n",
        "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "    return url.sub(r\"\", text)\n",
        "\n",
        "def remove_html(text):\n",
        "    html = re.compile(r\"<.*?>\")\n",
        "    return html.sub(r\"\", text)\n",
        "\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        \"]+\",\n",
        "        flags=re.UNICODE,\n",
        "    )\n",
        "    return emoji_pattern.sub(r\"\", string)\n",
        "\n",
        "def remove_punct(text):\n",
        "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
        "    return text.translate(table)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5ESVXOyxzK9",
        "outputId": "540ac041-9554-4ca8-dd13-b442d7bd8020"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgdEvka4wERJ"
      },
      "source": [
        "stop = set(stopwords.words(\"english\"))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
        "\n",
        "    return \" \".join(text)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrqwWWQ2uruM"
      },
      "source": [
        "# clean text\n",
        "# commenting out some preprocessing as charcnn does not need it\n",
        "# df['text'] = df['text'].map(lambda x: remove_URL(x))\n",
        "# df['text'] = df['text'].map(lambda x: remove_html(x))\n",
        "df['text'] = df['text'].map(lambda x: remove_emoji(x))\n",
        "# df['text'] = df['text'].map(lambda x: remove_punct(x))\n",
        "df['text'] = df[\"text\"].map(remove_stopwords)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrQ8S-WamUqF",
        "outputId": "ebf8be44-3f4f-49c6-8004-808bc19bbe23"
      },
      "source": [
        "# Count unique words\n",
        "def counter_word(text):\n",
        "    count = Counter()\n",
        "    for i in text.values:\n",
        "        for word in i.split():\n",
        "            count[word] += 1\n",
        "    return count\n",
        "\n",
        "text = df['text']\n",
        "\n",
        "counter = counter_word(text)\n",
        "num_words = len(counter)\n",
        "print (\"Number of words: \", num_words)\n",
        "\n",
        "# Max number of words in a sequence\n",
        "max_length = 250"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words:  230664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUCnYLkBpnNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc5bdc9-7b06-426d-d96f-941573dbaef8"
      },
      "source": [
        "# train-test split\n",
        "train_text, test_text, train_labels , test_labels = train_test_split(df['text'], df['fraudulent'] , test_size = 0.15)\n",
        "print(train_text.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15198,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHNBeD6dslhd",
        "outputId": "185dac44-2754-432c-babc-3d30b1f4dfa1"
      },
      "source": [
        "alphabet=\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
        "embedding_size = len(alphabet)\n",
        "input_size=1014\n",
        "num_of_classes=2\n",
        "dict = {}  # Maps each character to an integer\n",
        "for idx, char in enumerate(alphabet):\n",
        "  dict[char] = idx + 1\n",
        "\n",
        "print(embedding_size)\n",
        "print (dict)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69\n",
            "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '0': 27, '1': 28, '2': 29, '3': 30, '4': 31, '5': 32, '6': 33, '7': 34, '8': 35, '9': 36, '-': 60, ',': 38, ';': 39, '.': 40, '!': 41, '?': 42, ':': 43, \"'\": 44, '\"': 45, '/': 46, '\\\\': 47, '|': 48, '_': 49, '@': 50, '#': 51, '$': 52, '%': 53, '^': 54, '&': 55, '*': 56, '~': 57, '`': 58, '+': 59, '=': 61, '<': 62, '>': 63, '(': 64, ')': 65, '[': 66, ']': 67, '{': 68, '}': 69}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxU9Y3fL1jeU"
      },
      "source": [
        "# return one-hot-vector from string\n",
        "def str_to_ohv(s, ohv):\n",
        "  max_length = min(len(s), input_size)\n",
        "  for i in range(0, max_length):\n",
        "    c = s[i]\n",
        "    if c in dict:\n",
        "      ohv[i, dict[c]-1] = 1\n",
        "  return ohv"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XN07bKRWyr0m",
        "outputId": "ebb7a999-7b65-44d8-b114-8232c6ff480e"
      },
      "source": [
        "\"\"\"\n",
        "# test for the character-by-character encoding\n",
        "t = np.zeros((input_size, embedding_size))\n",
        "print (str_to_ohv(\"ab}\", t))\n",
        "\"\"\""
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# test for the character-by-character encoding\\nt = np.zeros((input_size, embedding_size))\\nprint (str_to_ohv(\"ab}\", t))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwyr--LJ_luP"
      },
      "source": [
        "num_jobs = train_text.shape[0]\n",
        "train_t = np.zeros((num_jobs, input_size, embedding_size), dtype=np.int8)\n",
        "i = 0\n",
        "for _, val in train_text.iteritems():\n",
        "  str_to_ohv(val, train_t[i])\n",
        "  i=i+1"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX_1JKmA6BZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638f5fb4-6798-4415-9392-3dc3a48e1c66"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(32, kernel_size=3, padding=\"valid\", activation=\"relu\", strides=1, input_shape=(input_size, embedding_size)))\n",
        "model.add(MaxPool1D(pool_size=3, padding=\"valid\"))\n",
        "model.add(Conv1D(32, kernel_size=3, padding=\"valid\", activation=\"relu\", strides=1, input_shape=(input_size, embedding_size)))\n",
        "model.add(MaxPool1D(pool_size=3, padding=\"valid\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "model.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy', tf.keras.metrics.FalsePositives(), tf.keras.metrics.FalseNegatives()])\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_2 (Conv1D)            (None, 1012, 32)          6656      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 337, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 335, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 111, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3552)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               454784    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 481,185\n",
            "Trainable params: 481,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7872Kjn0I6Gc",
        "outputId": "772c0818-c94a-4a3c-bef9-c5c21faba541"
      },
      "source": [
        "model.fit(train_t, train_labels, epochs = 10)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "475/475 [==============================] - 38s 78ms/step - loss: 0.2313 - accuracy: 0.9436 - false_positives_1: 13.9727 - false_negatives_1: 367.5651\n",
            "Epoch 2/10\n",
            "475/475 [==============================] - 36s 76ms/step - loss: 0.1360 - accuracy: 0.9531 - false_positives_1: 1.2143 - false_negatives_1: 353.7878\n",
            "Epoch 3/10\n",
            "475/475 [==============================] - 37s 78ms/step - loss: 0.0686 - accuracy: 0.9783 - false_positives_1: 22.5609 - false_negatives_1: 146.3571\n",
            "Epoch 4/10\n",
            "475/475 [==============================] - 37s 78ms/step - loss: 0.0390 - accuracy: 0.9868 - false_positives_1: 22.5420 - false_negatives_1: 78.9055\n",
            "Epoch 5/10\n",
            "475/475 [==============================] - 37s 78ms/step - loss: 0.0241 - accuracy: 0.9920 - false_positives_1: 18.3971 - false_negatives_1: 43.9601\n",
            "Epoch 6/10\n",
            "475/475 [==============================] - 37s 78ms/step - loss: 0.0153 - accuracy: 0.9941 - false_positives_1: 15.9580 - false_negatives_1: 27.8403\n",
            "Epoch 7/10\n",
            "475/475 [==============================] - 37s 78ms/step - loss: 0.0106 - accuracy: 0.9962 - false_positives_1: 9.3929 - false_negatives_1: 15.7605\n",
            "Epoch 8/10\n",
            "475/475 [==============================] - 37s 78ms/step - loss: 0.0081 - accuracy: 0.9978 - false_positives_1: 5.2773 - false_negatives_1: 14.3487\n",
            "Epoch 9/10\n",
            "475/475 [==============================] - 37s 78ms/step - loss: 0.0115 - accuracy: 0.9966 - false_positives_1: 11.2269 - false_negatives_1: 18.1660\n",
            "Epoch 10/10\n",
            "475/475 [==============================] - 37s 78ms/step - loss: 0.0070 - accuracy: 0.9975 - false_positives_1: 6.4958 - false_negatives_1: 8.8739\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8759482f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlXCalahJlar"
      },
      "source": [
        "num_jobs = test_text.shape[0]\n",
        "test_t = np.zeros((num_jobs, input_size, embedding_size), dtype=np.int8)\n",
        "i = 0\n",
        "for _, val in test_text.iteritems():\n",
        "  str_to_ohv(val, test_t[i])\n",
        "  i=i+1"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4B3OYymJPHW"
      },
      "source": [
        "pred_soft = model.predict(test_t)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci0Z6vXdJP2p",
        "outputId": "f1deceed-bfd2-4691-ff1c-d4e463bbae49"
      },
      "source": [
        "# pred = np.around(pred_soft, decimals = 0)\n",
        "pred = np.where(pred_soft > 0.15, 1, 0)\n",
        "\n",
        "acc = accuracy_score(pred, test_labels)\n",
        "f1 = f1_score(pred, test_labels)\n",
        "\n",
        "cm = confusion_matrix(test_labels, pred)\n",
        "tn = cm[0][0]\n",
        "fn = cm[1][0]\n",
        "tp = cm[1][1]\n",
        "fp = cm[0][1]\n",
        "\n",
        "print('Accuracy score: {:.4f}'.format(acc), 'F1 score: {:.4f}'.format(f1))\n",
        "print('False Positives: {:.0f}'.format(fp), 'False Negatives: {:.0f}'.format(fn))\n",
        "print('Confusion matrix:\\n', cm)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.9739 F1 score: 0.7083\n",
            "False Positives: 11 False Negatives: 59\n",
            "Confusion matrix:\n",
            " [[2527   11]\n",
            " [  59   85]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm1MoM4U4aQa",
        "outputId": "dcdddf49-8fbd-41ee-de36-9be0637d6f2a"
      },
      "source": [
        "auc = roc_auc_score(test_labels, pred_soft)\n",
        "print('AUC score: {:.4f}'.format(auc))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score: 0.9448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs5eiI4RPuHT",
        "outputId": "cdd80817-fc6b-472a-b368-047349c6c482"
      },
      "source": [
        "\"\"\"\"\n",
        "# Uncomment to save results on drive to a csv file\n",
        "df_results1 = pd.DataFrame(data=test_labels)\n",
        "df_results1.reset_index(drop=True, inplace=True)\n",
        "df_results2 = pd.DataFrame(data=pred_soft, columns=['char_cnn'])\n",
        "df_results = pd.concat([df_results1, df_results2], axis=1)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "results_file='/content/drive/My Drive/Results/fj_char_cnn.csv'\n",
        "\n",
        "df_results.to_csv(results_file)\n",
        "\"\"\""
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}