{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fj_embedding_composite.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNtThuBWbpeQMSbJ3yFRLMB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-dube/fakejobs/blob/main/fj_embedding_composite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFWTUL3GCHsG"
      },
      "source": [
        "# Load the modules used\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, GlobalMaxPool1D, Conv1D, MaxPool1D, Flatten, RepeatVector, Input, Embedding, Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras import metrics\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wN7spE3GCrZ"
      },
      "source": [
        "# For reproducible results, set seeds\n",
        "import random as rn\n",
        "import os\n",
        "import tensorflow as tf\n",
        "os.environ['PYTHONHASHSEED'] = '42'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
        "np.random.seed(42)\n",
        "rn.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrnTamUHDzxI"
      },
      "source": [
        "# Set data_url, the location of the data\n",
        "# Data is not loaded from a local file\n",
        "# data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fj_small.csv\"\n",
        "# data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fj_medium.csv\"\n",
        "data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fake_job_postings.csv\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usYPD_l1Bimz"
      },
      "source": [
        "def fj_load_df_from_url():\n",
        "    \"\"\"\n",
        "    Load dataframe from csv file\n",
        "    Input:\n",
        "        None\n",
        "    Returns:\n",
        "        dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(data_url)\n",
        "\n",
        "    print ('Loaded dataframe shape', df.shape)\n",
        "\n",
        "    counts = fj_label_stats(df)\n",
        "    print ('Not fraudulent', counts[0], 'Fraudulent', counts[1])\n",
        "\n",
        "    print(df.describe())\n",
        "\n",
        "    print ('NAs/NANs in data =>')\n",
        "    print(df.isna().sum())\n",
        "\n",
        "    return df\n",
        "\n",
        "def fj_label_stats(df):\n",
        "    \"\"\"\n",
        "    Very basic label statistics\n",
        "    Input: \n",
        "        Dataframe\n",
        "    Returns:\n",
        "        Number of samples with 0, 1 as the label\n",
        "    \"\"\"\n",
        "    counts = np.bincount(df['fraudulent'])\n",
        "    return counts\n",
        "\n",
        "def fj_txt_only(df):\n",
        "    \"\"\"\n",
        "    Combine all the text fields, discard everything else except for the label\n",
        "    Input: \n",
        "        Dataframe\n",
        "    Returns:\n",
        "        Processed dataframe\n",
        "    \"\"\"\n",
        "    \n",
        "    df.fillna(\" \", inplace = True)\n",
        "\n",
        "    df['text'] = df['title'] + ' ' + df['location'] + ' ' + df['department'] + \\\n",
        "    ' ' + df['company_profile'] + ' ' + df['description'] + ' ' + \\\n",
        "    df['requirements'] + ' ' + df['benefits'] + ' ' + df['employment_type'] + \\\n",
        "    ' ' + df['required_education'] + ' ' + df['industry'] + ' ' + df['function'] \n",
        "\n",
        "    del df['title']\n",
        "    del df['location']\n",
        "    del df['department']\n",
        "    del df['company_profile']\n",
        "    del df['description']\n",
        "    del df['requirements']\n",
        "    del df['benefits']\n",
        "    del df['employment_type']\n",
        "    del df['required_experience']\n",
        "    del df['required_education']\n",
        "    del df['industry']\n",
        "    del df['function']  \n",
        "    \n",
        "    del df['salary_range']\n",
        "    del df['job_id']\n",
        "    del df['telecommuting']\n",
        "    del df['has_company_logo']\n",
        "    del df['has_questions']\n",
        "\n",
        "    return df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lks9Mm0Tc1l2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00c0a0d5-54c7-4ad6-a29c-0f98d99735b3"
      },
      "source": [
        "df = fj_load_df_from_url()\n",
        "df = fj_txt_only(df)\n",
        "print('Maximum text length', df['text'].str.len().max())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded dataframe shape (17880, 18)\n",
            "Not fraudulent 17014 Fraudulent 866\n",
            "             job_id  telecommuting  ...  has_questions    fraudulent\n",
            "count  17880.000000   17880.000000  ...   17880.000000  17880.000000\n",
            "mean    8940.500000       0.042897  ...       0.491723      0.048434\n",
            "std     5161.655742       0.202631  ...       0.499945      0.214688\n",
            "min        1.000000       0.000000  ...       0.000000      0.000000\n",
            "25%     4470.750000       0.000000  ...       0.000000      0.000000\n",
            "50%     8940.500000       0.000000  ...       0.000000      0.000000\n",
            "75%    13410.250000       0.000000  ...       1.000000      0.000000\n",
            "max    17880.000000       1.000000  ...       1.000000      1.000000\n",
            "\n",
            "[8 rows x 5 columns]\n",
            "NAs/NANs in data =>\n",
            "job_id                     0\n",
            "title                      0\n",
            "location                 346\n",
            "department             11547\n",
            "salary_range           15012\n",
            "company_profile         3308\n",
            "description                1\n",
            "requirements            2695\n",
            "benefits                7210\n",
            "telecommuting              0\n",
            "has_company_logo           0\n",
            "has_questions              0\n",
            "employment_type         3471\n",
            "required_experience     7050\n",
            "required_education      8105\n",
            "industry                4903\n",
            "function                6455\n",
            "fraudulent                 0\n",
            "dtype: int64\n",
            "Maximum text length 14991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxtcnlHBpPro"
      },
      "source": [
        "# Utilities to clean text\n",
        "\n",
        "def remove_URL(text):\n",
        "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "    return url.sub(r\"\", text)\n",
        "\n",
        "def remove_html(text):\n",
        "    html = re.compile(r\"<.*?>\")\n",
        "    return html.sub(r\"\", text)\n",
        "\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        \"]+\",\n",
        "        flags=re.UNICODE,\n",
        "    )\n",
        "    return emoji_pattern.sub(r\"\", string)\n",
        "\n",
        "def remove_punct(text):\n",
        "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
        "    return text.translate(table)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5ESVXOyxzK9",
        "outputId": "7ae03e0e-80f6-4cdf-b8af-a06f378c6f77"
      },
      "source": [
        "# more text cleaning - remove stopwords using NLTK\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = set(stopwords.words(\"english\"))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
        "\n",
        "    return \" \".join(text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrqwWWQ2uruM"
      },
      "source": [
        "# Actually clean the text\n",
        "df['text'] = df['text'].map(lambda x: remove_URL(x))\n",
        "df['text'] = df['text'].map(lambda x: remove_html(x))\n",
        "df['text'] = df['text'].map(lambda x: remove_emoji(x))\n",
        "df['text'] = df['text'].map(lambda x: remove_punct(x))\n",
        "df['text'] = df[\"text\"].map(remove_stopwords)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUCnYLkBpnNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "873807e0-fe65-4cb2-aab6-23cd28b4b7e8"
      },
      "source": [
        "# train-test split\n",
        "train_text, test_text, train_labels , test_labels = train_test_split(df['text'], df['fraudulent'] , test_size = 0.15)\n",
        "print(train_text.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15198,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1QfnRxKUxlV"
      },
      "source": [
        "# Token model: Configuration parameters\n",
        "max_num_words = 50000 # maximum allowed size of vocabulary\n",
        "max_length = 250 # maximum allowed number of words in a job description\n",
        "embed_dim = 32 # number of dimensions for learned embedding\n",
        "# settimg embedding_dim to 50 as min globe embedding size available is 50"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW2n8ilFghmh",
        "outputId": "2019ace5-e79e-457c-a50b-fe3af0caf62d"
      },
      "source": [
        "# Token model: Prepare the token based train and test input\n",
        "\n",
        "# max_num_words variable in case we want to clip the number of words\n",
        "tokenizer = Tokenizer(num_words=max_num_words)\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "\n",
        "num_tokens = len(tokenizer.word_index)\n",
        "print(\"Found %s unique tokens.\" % num_tokens)\n",
        "\n",
        "# Fix dictionary for later use when embeddings are loaded\n",
        "# While the vocabulary size is restricted to max_num_words above\n",
        "#   the dictionary returned by the Tokenizer has values outside of max_num_words\n",
        "#   the embedding loading code needs all values to be in range\n",
        "tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() if i < max_num_words}\n",
        "\n",
        "# handle the case where the number of tokens < max_num_words, the max size of dictionary\n",
        "max_num_words = min(num_tokens + 1, max_num_words)\n",
        "print(\"Set %s max_num_words.\" % max_num_words)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_text)\n",
        "train_padded = pad_sequences(\n",
        "    train_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
        ")\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_text)\n",
        "test_padded = pad_sequences(\n",
        "    test_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
        ")\n",
        "\n",
        "print(f\"Shape of train {train_padded.shape}\")\n",
        "print(f\"Shape of test {test_padded.shape}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 157210 unique tokens.\n",
            "Set 50000 max_num_words.\n",
            "Shape of train (15198, 250)\n",
            "Shape of test (2682, 250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EtPnDS0s8lgb",
        "outputId": "a5895e01-60fd-4f58-c3a6-b84a844972aa"
      },
      "source": [
        "\"\"\"\n",
        "# test to ensure that there are no out of index values in dictionary\n",
        "print(word_index[\"cma\"])\n",
        "\"\"\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# test to ensure that there are no out of index values in dictionary\\nprint(word_index[\"cma\"])\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "bXbz_ym-4XN7",
        "outputId": "9f975358-cce1-4505-eb38-013383c1e3fb"
      },
      "source": [
        "\"\"\" \n",
        "# Uncomment if using GLOVE\"\n",
        "# Token model: Assumes that GLOVE data is available on locally mounted drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "glove_file='/content/drive/My Drive/Data/glove.6B.50d.txt'\n",
        "\"\"\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' \\n# Uncomment if using GLOVE\"\\n# Token model: Assumes that GLOVE data is available on locally mounted drive\\nfrom google.colab import drive\\ndrive.mount(\\'/content/drive\\')\\nglove_file=\\'/content/drive/My Drive/Data/glove.6B.50d.txt\\'\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "qMB3dxgixiXR",
        "outputId": "ea375909-c1a4-4655-f8c3-6e9f5d58c655"
      },
      "source": [
        "\"\"\" \n",
        "# Uncomment if using GLOVE\"\n",
        "\n",
        "# Token model: load in pre-trained GLOVE word vectors\n",
        "print('Loading word vectors...')\n",
        "word2vec = {}\n",
        "with open(glove_file,encoding=\"utf8\") as f:\n",
        "    # is just a space-separated text file in the format:\n",
        "    # word vec[0] vec[1] vec[2] ...\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vec = np.asarray(values[1:], dtype='float32')\n",
        "        word2vec[word] = vec\n",
        "print('Found %s word vectors.' % len(word2vec))\n",
        "\"\"\""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' \\n# Uncomment if using GLOVE\"\\n\\n# Token model: load in pre-trained GLOVE word vectors\\nprint(\\'Loading word vectors...\\')\\nword2vec = {}\\nwith open(glove_file,encoding=\"utf8\") as f:\\n    # is just a space-separated text file in the format:\\n    # word vec[0] vec[1] vec[2] ...\\n    for line in f:\\n        values = line.split()\\n        word = values[0]\\n        vec = np.asarray(values[1:], dtype=\\'float32\\')\\n        word2vec[word] = vec\\nprint(\\'Found %s word vectors.\\' % len(word2vec))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Vm9_ZTcsxsRo",
        "outputId": "088e580d-6baf-4f5e-d2d9-d53f95efd787"
      },
      "source": [
        "\"\"\" \n",
        "# Uncomment if using GLOVE\"\n",
        "\n",
        "# Token model: prepare embedding matrix\n",
        "print('Filling pre-trained embeddings...')\n",
        "embedding_matrix = np.zeros((max_num_words, embed_dim))\n",
        "for word, i in word_index.items():\n",
        "      embedding_vector = word2vec.get(word)\n",
        "      if embedding_vector is not None:\n",
        "          # words not found in embedding index will be all zeros.\n",
        "          embedding_matrix[i] = embedding_vector\n",
        "\"\"\""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' \\n# Uncomment if using GLOVE\"\\n\\n# Token model: prepare embedding matrix\\nprint(\\'Filling pre-trained embeddings...\\')\\nembedding_matrix = np.zeros((max_num_words, embed_dim))\\nfor word, i in word_index.items():\\n      embedding_vector = word2vec.get(word)\\n      if embedding_vector is not None:\\n          # words not found in embedding index will be all zeros.\\n          embedding_matrix[i] = embedding_vector\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMgPGUA7r-kn",
        "outputId": "77347e7a-b92e-4fc3-8893-cf5abb10a6cf"
      },
      "source": [
        "# Token model: Assumes that FASTTEXT data is available on locally mounted drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "fasttext_file='/content/drive/My Drive/Data/gensim.mod'"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3arnmZvsN8_",
        "outputId": "6afdd469-3638-4e5d-b437-afc0a5244d11"
      },
      "source": [
        "# Token model: load in pre-trained FASTTEXT word vectors\n",
        "print('Loading word vectors...')\n",
        "from gensim.models.fasttext import FastText as FT_gensim\n",
        "loaded_model = FT_gensim.load(fasttext_file)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qccgh_D5s4nW",
        "outputId": "478c4521-b057-4305-8e1f-3e50ef022ccf"
      },
      "source": [
        "# Token model: prepare embedding matrix\n",
        "print('Filling pre-trained embeddings...')\n",
        "embedding_matrix = np.zeros((max_num_words, embed_dim))\n",
        "for word, i in word_index.items():\n",
        "      # XXX not sure why gensim uses the quotes below\n",
        "      if (\"word\" in loaded_model):\n",
        "          embedding_matrix[i] = loaded_model[\"word\"]\n",
        "          # word's vector not found in embedding index will be all zeros."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filling pre-trained embeddings...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DKTG8ya5cUC",
        "outputId": "af11a946-5ec4-406b-b56c-ce223e0d6c6f"
      },
      "source": [
        "# Token model: test for embedding\n",
        "word=\"salary\"\n",
        "print(word)\n",
        "if (\"word\" in loaded_model):\n",
        "  print (loaded_model[\"word\"])\n",
        "else:\n",
        "  print (\"no vector\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "salary\n",
            "[ 6.6886992  -3.282141   -3.6494393  -1.2635535  -1.2110971  -0.8512291\n",
            " -0.16059165  4.1612988   0.95718175  6.2024746   4.1998453  -0.41140395\n",
            "  1.7679561  -0.95623416  1.5070729   4.0457788  -0.2256046  -6.3139067\n",
            "  0.90753096 -1.0949931  -1.0299804  -1.2630032   6.0217357   2.7677934\n",
            " -5.6800394   1.9692799  -9.576719    1.2885904  -5.8050404  -2.9074304\n",
            "  9.0303755   4.5721536 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_g3Yeivx0r7"
      },
      "source": [
        "# Token model: load pre-trained word embeddings into an Embedding layer\n",
        "# note that we set trainable = True so as to allow the embedding layer to be trained further\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "  max_num_words,\n",
        "  embed_dim,\n",
        "  weights=[embedding_matrix],\n",
        "  input_length=max_length,\n",
        "  trainable=True\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHNBeD6dslhd",
        "outputId": "1b9bbef0-ca91-46b7-abba-cae6c5091dde"
      },
      "source": [
        "# Char model: Configuration parameters\n",
        "\n",
        "# Assuming that the text has been processed for word tokenization\n",
        "# alphabet=\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
        "alphabet=\"abcdefghijklmnopqrstuvwxyz0123456789\"\n",
        "encoding_size = len(alphabet)\n",
        "char_input_size=1000\n",
        "\n",
        "# Create a dictionary for encoding characters\n",
        "dict = {}  # Maps each character to an integer\n",
        "for idx, char in enumerate(alphabet):\n",
        "  dict[char] = idx + 1\n",
        "\n",
        "print(encoding_size)\n",
        "print (dict)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36\n",
            "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '0': 27, '1': 28, '2': 29, '3': 30, '4': 31, '5': 32, '6': 33, '7': 34, '8': 35, '9': 36}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxU9Y3fL1jeU"
      },
      "source": [
        "# Char model: Utility function(s)\n",
        "\n",
        "# Return one-hot-vector character encoding for string\n",
        "# Memory is allocated outside this routine\n",
        "def str_to_ohv(s, ohv):\n",
        "  max_length = min(len(s), char_input_size)\n",
        "  for i in range(0, max_length):\n",
        "    c = s[i]\n",
        "    if c in dict:\n",
        "      ohv[i, dict[c]-1] = 1\n",
        "  return ohv"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwyr--LJ_luP"
      },
      "source": [
        "# Char model: create train input\n",
        "num_jobs = train_text.shape[0]\n",
        "train_t = np.zeros((num_jobs, char_input_size, encoding_size), dtype=np.int8)\n",
        "i = 0\n",
        "for _, val in train_text.iteritems():\n",
        "  str_to_ohv(val, train_t[i])\n",
        "  i=i+1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlXCalahJlar"
      },
      "source": [
        "# Char model: create test input\n",
        "num_jobs = test_text.shape[0]\n",
        "test_t = np.zeros((num_jobs, char_input_size, encoding_size), dtype=np.int8)\n",
        "i = 0\n",
        "for _, val in test_text.iteritems():\n",
        "  str_to_ohv(val, test_t[i])\n",
        "  i=i+1"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX_1JKmA6BZy"
      },
      "source": [
        "# The Composite model: Token + Char\n",
        "\n",
        "# Not specificying input dtype as Keras internally assumes float32\n",
        "\n",
        "# Token (word) model\n",
        "token_input = Input(shape=(max_length,), name=\"token_input\")\n",
        "token_embedding = embedding_layer(token_input)\n",
        "token_conv = Conv1D(64, kernel_size=3, strides=1, padding=\"valid\", activation=\"relu\", name=\"token_conv\")(token_embedding)\n",
        "token_pool = MaxPool1D(pool_size=3, strides=3, name=\"token_pool\")(token_conv)\n",
        "token_drop = Dropout(.5, name=\"token_drop\")(token_pool)\n",
        "\n",
        "# Char model\n",
        "char_input = Input(shape=(char_input_size, encoding_size), name=\"char_input\")\n",
        "char_conv = Conv1D(64, kernel_size=3, strides=1, padding=\"valid\",activation=\"relu\", name=\"char_conv\")(char_input)\n",
        "char_pool = GlobalMaxPool1D(name=\"char_pool\")(char_conv)\n",
        "char_drop = Dropout(.5, name=\"char_drop\")(char_pool)\n",
        "char_repeated = RepeatVector(token_drop.get_shape()[1], name=\"char_repeated\")(char_drop)\n",
        "\n",
        "# Merge\n",
        "merged = Concatenate(axis=2, name=\"concat\")([token_drop, char_repeated])\n",
        "lstm = Bidirectional(LSTM(32, dropout=0.3, recurrent_dropout=0.01, name=\"lstm\"), name=\"bidir\")(merged)\n",
        "output = Dense(1, activation=\"sigmoid\", name=\"output\")(lstm)\n",
        "\n",
        "# define a model with a list of two inputs\n",
        "model = Model(inputs=[token_input, char_input], outputs=output)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUzcT443YL0U",
        "outputId": "c7873a42-32ad-499c-eea4-a720e71051e0"
      },
      "source": [
        "model.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy', tf.keras.metrics.FalsePositives(), tf.keras.metrics.FalseNegatives()])\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "token_input (InputLayer)        [(None, 250)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_input (InputLayer)         [(None, 1000, 36)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 250, 32)      1600000     token_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "char_conv (Conv1D)              (None, 998, 64)      6976        char_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "token_conv (Conv1D)             (None, 248, 64)      6208        embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "char_pool (GlobalMaxPooling1D)  (None, 64)           0           char_conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "token_pool (MaxPooling1D)       (None, 82, 64)       0           token_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "char_drop (Dropout)             (None, 64)           0           char_pool[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "token_drop (Dropout)            (None, 82, 64)       0           token_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "char_repeated (RepeatVector)    (None, 82, 64)       0           char_drop[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concat (Concatenate)            (None, 82, 128)      0           token_drop[0][0]                 \n",
            "                                                                 char_repeated[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidir (Bidirectional)           (None, 64)           41216       concat[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            65          bidir[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 1,654,465\n",
            "Trainable params: 1,654,465\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "KdX53khljBIf",
        "outputId": "1b145d92-1f53-4e76-af9f-bf653a5d8218"
      },
      "source": [
        "\"\"\"\n",
        "# Uncomment to save image of model architecture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dot_img_file = '/content/drive/My Drive/Results/fj_embedding_composite.png'\n",
        "tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True, show_dtype=True)\n",
        "\"\"\""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# Uncomment to save image of model architecture\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n\\ndot_img_file = '/content/drive/My Drive/Results/fj_embedding_composite.png'\\ntf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True, show_dtype=True)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7872Kjn0I6Gc",
        "outputId": "1b65fc6d-dd1d-43c3-df39-ad9ab3cf4fc7"
      },
      "source": [
        "model.fit([train_padded, train_t], train_labels, epochs = 7)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "475/475 [==============================] - 114s 228ms/step - loss: 0.2195 - accuracy: 0.9362 - false_positives: 30.9685 - false_negatives: 368.5651\n",
            "Epoch 2/7\n",
            "475/475 [==============================] - 112s 236ms/step - loss: 0.1845 - accuracy: 0.9520 - false_positives: 0.0000e+00 - false_negatives: 369.0924\n",
            "Epoch 3/7\n",
            "475/475 [==============================] - 108s 228ms/step - loss: 0.1774 - accuracy: 0.9529 - false_positives: 0.0000e+00 - false_negatives: 366.4328\n",
            "Epoch 4/7\n",
            "475/475 [==============================] - 109s 229ms/step - loss: 0.1718 - accuracy: 0.9550 - false_positives: 0.0903 - false_negatives: 352.0504\n",
            "Epoch 5/7\n",
            "475/475 [==============================] - 108s 228ms/step - loss: 0.1747 - accuracy: 0.9496 - false_positives: 3.7983 - false_negatives: 367.1870\n",
            "Epoch 6/7\n",
            "475/475 [==============================] - 108s 228ms/step - loss: 0.1634 - accuracy: 0.9534 - false_positives: 24.5651 - false_negatives: 330.7143\n",
            "Epoch 7/7\n",
            "475/475 [==============================] - 108s 227ms/step - loss: 0.1522 - accuracy: 0.9576 - false_positives: 19.7983 - false_negatives: 302.3929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa0b1843978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4B3OYymJPHW"
      },
      "source": [
        "pred_soft = model.predict([test_padded, test_t])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci0Z6vXdJP2p",
        "outputId": "37fe0821-4cbe-4310-cad1-7c5f06c29d31"
      },
      "source": [
        "# pred = np.around(pred_soft, decimals = 0)\n",
        "pred = np.where(pred_soft > 0.15, 1, 0)\n",
        "\n",
        "acc = accuracy_score(pred, test_labels)\n",
        "f1 = f1_score(pred, test_labels)\n",
        "\n",
        "cm = confusion_matrix(test_labels, pred)\n",
        "tn = cm[0][0]\n",
        "fn = cm[1][0]\n",
        "tp = cm[1][1]\n",
        "fp = cm[0][1]\n",
        "\n",
        "print('Accuracy score: {:.4f}'.format(acc), 'F1 score: {:.4f}'.format(f1))\n",
        "print('False Positives: {:.0f}'.format(fp), 'False Negatives: {:.0f}'.format(fn))\n",
        "print('Confusion matrix:\\n', cm)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.9627 F1 score: 0.5370\n",
            "False Positives: 14 False Negatives: 86\n",
            "Confusion matrix:\n",
            " [[2524   14]\n",
            " [  86   58]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm1MoM4U4aQa",
        "outputId": "2773b7fb-33ae-466a-becf-10e0393a4baf"
      },
      "source": [
        "auc = roc_auc_score(test_labels, pred_soft)\n",
        "print('AUC score: {:.4f}'.format(auc))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score: 0.9274\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}