{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fj_embedding_composite.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsD5UXDSL+TGN4lemCLh32",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-dube/fakejobs/blob/main/fj_embedding_composite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFWTUL3GCHsG"
      },
      "source": [
        "# Load the modules used\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, GlobalMaxPool1D, Conv1D, MaxPool1D, Flatten, RepeatVector, Input, Embedding, Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras import metrics\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wN7spE3GCrZ"
      },
      "source": [
        "# For reproducible results, set seeds\n",
        "import random as rn\n",
        "import os\n",
        "import tensorflow as tf\n",
        "os.environ['PYTHONHASHSEED'] = '42'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
        "np.random.seed(42)\n",
        "rn.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrnTamUHDzxI"
      },
      "source": [
        "# Set data_url, the location of the data\n",
        "# Data is not loaded from a local file\n",
        "# data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fj_small.csv\"\n",
        "# data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fj_medium.csv\"\n",
        "data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fake_job_postings.csv\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usYPD_l1Bimz"
      },
      "source": [
        "def fj_load_df_from_url():\n",
        "    \"\"\"\n",
        "    Load dataframe from csv file\n",
        "    Input:\n",
        "        None\n",
        "    Returns:\n",
        "        dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(data_url)\n",
        "\n",
        "    print ('Loaded dataframe shape', df.shape)\n",
        "\n",
        "    counts = fj_label_stats(df)\n",
        "    print ('Not fraudulent', counts[0], 'Fraudulent', counts[1])\n",
        "\n",
        "    print(df.describe())\n",
        "\n",
        "    print ('NAs/NANs in data =>')\n",
        "    print(df.isna().sum())\n",
        "\n",
        "    return df\n",
        "\n",
        "def fj_label_stats(df):\n",
        "    \"\"\"\n",
        "    Very basic label statistics\n",
        "    Input: \n",
        "        Dataframe\n",
        "    Returns:\n",
        "        Number of samples with 0, 1 as the label\n",
        "    \"\"\"\n",
        "    counts = np.bincount(df['fraudulent'])\n",
        "    return counts\n",
        "\n",
        "def fj_txt_only(df):\n",
        "    \"\"\"\n",
        "    Combine all the text fields, discard everything else except for the label\n",
        "    Input: \n",
        "        Dataframe\n",
        "    Returns:\n",
        "        Processed dataframe\n",
        "    \"\"\"\n",
        "    \n",
        "    df.fillna(\" \", inplace = True)\n",
        "\n",
        "    df['text'] = df['title'] + ' ' + df['location'] + ' ' + df['department'] + \\\n",
        "    ' ' + df['company_profile'] + ' ' + df['description'] + ' ' + \\\n",
        "    df['requirements'] + ' ' + df['benefits'] + ' ' + df['employment_type'] + \\\n",
        "    ' ' + df['required_education'] + ' ' + df['industry'] + ' ' + df['function'] \n",
        "\n",
        "    del df['title']\n",
        "    del df['location']\n",
        "    del df['department']\n",
        "    del df['company_profile']\n",
        "    del df['description']\n",
        "    del df['requirements']\n",
        "    del df['benefits']\n",
        "    del df['employment_type']\n",
        "    del df['required_experience']\n",
        "    del df['required_education']\n",
        "    del df['industry']\n",
        "    del df['function']  \n",
        "    \n",
        "    del df['salary_range']\n",
        "    del df['job_id']\n",
        "    del df['telecommuting']\n",
        "    del df['has_company_logo']\n",
        "    del df['has_questions']\n",
        "\n",
        "    return df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lks9Mm0Tc1l2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51619521-91ee-4e66-ec35-dcf613231ee4"
      },
      "source": [
        "df = fj_load_df_from_url()\n",
        "df = fj_txt_only(df)\n",
        "print('Maximum text length', df['text'].str.len().max())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded dataframe shape (17880, 18)\n",
            "Not fraudulent 17014 Fraudulent 866\n",
            "             job_id  telecommuting  ...  has_questions    fraudulent\n",
            "count  17880.000000   17880.000000  ...   17880.000000  17880.000000\n",
            "mean    8940.500000       0.042897  ...       0.491723      0.048434\n",
            "std     5161.655742       0.202631  ...       0.499945      0.214688\n",
            "min        1.000000       0.000000  ...       0.000000      0.000000\n",
            "25%     4470.750000       0.000000  ...       0.000000      0.000000\n",
            "50%     8940.500000       0.000000  ...       0.000000      0.000000\n",
            "75%    13410.250000       0.000000  ...       1.000000      0.000000\n",
            "max    17880.000000       1.000000  ...       1.000000      1.000000\n",
            "\n",
            "[8 rows x 5 columns]\n",
            "NAs/NANs in data =>\n",
            "job_id                     0\n",
            "title                      0\n",
            "location                 346\n",
            "department             11547\n",
            "salary_range           15012\n",
            "company_profile         3308\n",
            "description                1\n",
            "requirements            2695\n",
            "benefits                7210\n",
            "telecommuting              0\n",
            "has_company_logo           0\n",
            "has_questions              0\n",
            "employment_type         3471\n",
            "required_experience     7050\n",
            "required_education      8105\n",
            "industry                4903\n",
            "function                6455\n",
            "fraudulent                 0\n",
            "dtype: int64\n",
            "Maximum text length 14991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxtcnlHBpPro"
      },
      "source": [
        "# Utilities to clean text\n",
        "\n",
        "def remove_URL(text):\n",
        "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "    return url.sub(r\"\", text)\n",
        "\n",
        "def remove_html(text):\n",
        "    html = re.compile(r\"<.*?>\")\n",
        "    return html.sub(r\"\", text)\n",
        "\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        \"]+\",\n",
        "        flags=re.UNICODE,\n",
        "    )\n",
        "    return emoji_pattern.sub(r\"\", string)\n",
        "\n",
        "def remove_punct(text):\n",
        "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
        "    return text.translate(table)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5ESVXOyxzK9",
        "outputId": "7bc8bbe4-ec28-4517-d3c7-1a1967b57f75"
      },
      "source": [
        "# more text cleaning - remove stopwords using NLTK\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = set(stopwords.words(\"english\"))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
        "\n",
        "    return \" \".join(text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrqwWWQ2uruM"
      },
      "source": [
        "# Actually clean the text\n",
        "df['text'] = df['text'].map(lambda x: remove_URL(x))\n",
        "df['text'] = df['text'].map(lambda x: remove_html(x))\n",
        "df['text'] = df['text'].map(lambda x: remove_emoji(x))\n",
        "df['text'] = df['text'].map(lambda x: remove_punct(x))\n",
        "df['text'] = df[\"text\"].map(remove_stopwords)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUCnYLkBpnNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97634049-ff77-46a6-a963-6dec8273006b"
      },
      "source": [
        "# train-test split\n",
        "train_text, test_text, train_labels , test_labels = train_test_split(df['text'], df['fraudulent'] , test_size = 0.15)\n",
        "print(train_text.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15198,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1QfnRxKUxlV"
      },
      "source": [
        "# Token model: Configuration parameters\n",
        "max_num_words = 50000 # maximum allowed size of vocabulary\n",
        "max_length = 250 # maximum allowed number of words in a job description\n",
        "embed_dim = 32 # number of dimensions for learned embedding\n",
        "# settimg embedding_dim to 50 as min globe embedding size available is 50"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW2n8ilFghmh",
        "outputId": "0adbc065-e1ec-4eb5-e95a-7a014d24fd9d"
      },
      "source": [
        "# Token model: Prepare the token based train and test input\n",
        "\n",
        "# max_num_words variable in case we want to clip the number of words\n",
        "tokenizer = Tokenizer(num_words=max_num_words)\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "\n",
        "num_tokens = len(tokenizer.word_index)\n",
        "print(\"Found %s unique tokens.\" % num_tokens)\n",
        "\n",
        "# Fix dictionary for later use when embeddings are loaded\n",
        "# While the vocabulary size is restricted to max_num_words above\n",
        "#   the dictionary returned by the Tokenizer has values outside of max_num_words\n",
        "#   the embedding loading code needs all values to be in range\n",
        "tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() if i < max_num_words}\n",
        "\n",
        "# handle the case where the number of tokens < max_num_words, the max size of dictionary\n",
        "max_num_words = min(num_tokens + 1, max_num_words)\n",
        "print(\"Set %s max_num_words.\" % max_num_words)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_text)\n",
        "train_padded = pad_sequences(\n",
        "    train_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
        ")\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_text)\n",
        "test_padded = pad_sequences(\n",
        "    test_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
        ")\n",
        "\n",
        "print(f\"Shape of train {train_padded.shape}\")\n",
        "print(f\"Shape of test {test_padded.shape}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 157210 unique tokens.\n",
            "Set 50000 max_num_words.\n",
            "Shape of train (15198, 250)\n",
            "Shape of test (2682, 250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EtPnDS0s8lgb",
        "outputId": "35ffe5bc-7e38-4009-c4f4-e73c80a96b72"
      },
      "source": [
        "\"\"\"\n",
        "# test to ensure that there are no out of index values in dictionary\n",
        "print(word_index[\"cma\"])\n",
        "\"\"\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# test to ensure that there are no out of index values in dictionary\\nprint(word_index[\"cma\"])\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMgPGUA7r-kn",
        "outputId": "14b346d1-ee11-494f-9219-3e9d82d49edf"
      },
      "source": [
        "\n",
        "# Token model: but with FASTTEXT (use either FASTTEXT or word2vec but not both)\n",
        "# Token model: Assumes that FASTTEXT data is available on locally mounted drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "fasttext_file='/content/drive/My Drive/Data/fakejobs/gensim_fasttext.mod'\n",
        "\n",
        "# Token model: load in pre-trained FASTTEXT word vectors\n",
        "print('Loading word vectors...')\n",
        "from gensim.models.fasttext import FastText as FT_gensim\n",
        "loaded_model = FT_gensim.load(fasttext_file)\n",
        "\n",
        "print('Filling pre-trained embeddings...')\n",
        "embedding_matrix = np.zeros((max_num_words, embed_dim))\n",
        "for word, i in word_index.items():\n",
        "      # XXX not sure why gensim uses the quotes below\n",
        "      if (\"word\" in loaded_model):\n",
        "          embedding_matrix[i] = loaded_model[\"word\"]\n",
        "          # word's vector not found in embedding index will be all zeros.\n",
        "\n",
        "word=\"salary\"\n",
        "print(word)\n",
        "if (\"word\" in loaded_model):\n",
        "  print (loaded_model[\"word\"])\n",
        "else:\n",
        "  print (\"no vector\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loading word vectors...\n",
            "Filling pre-trained embeddings...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "salary\n",
            "[-1.5110339  -4.7917013  -6.0797024   4.158937    0.48231736  2.0108404\n",
            "  5.210091    1.6388749  -2.5137873  -5.611999    8.081213    9.79396\n",
            "  2.3139238  -0.16253696  2.0708086   3.0841942  -0.87787366 -0.9708962\n",
            " 11.168563    5.1884975  -5.557217    1.9740692   7.166332   -6.4427824\n",
            " -9.780313    7.2287827   2.884714    1.0802897  -0.96907353 -3.0243003\n",
            "  7.115761    2.6194994 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "evHj8J2MjwMS",
        "outputId": "ed6d5033-e17c-4b34-b62d-f95422819574"
      },
      "source": [
        "\"\"\"\n",
        "# Token model: but with word2vec (use either FASTTEXT or word2vec but not both)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import gensim.models\n",
        "word2vec_file='/content/drive/My Drive/Data/fakejobs/gensim_word2vec.mod'\n",
        "\n",
        "print('Loading word vectors...')\n",
        "loaded_model = gensim.models.Word2Vec.load(word2vec_file)\n",
        "\n",
        "# Token model: prepare embedding matrix\n",
        "print('Filling pre-trained embeddings...')\n",
        "embedding_matrix = np.zeros((max_num_words, embed_dim))\n",
        "for word, i in word_index.items():\n",
        "      if (word in loaded_model.wv.vocab):\n",
        "          embedding_matrix[i] = loaded_model[word]\n",
        "          # word's vector not found in embedding index will be all zeros.\n",
        "\n",
        "word=\"salary\"\n",
        "print(word)\n",
        "if (word in loaded_model.wv.vocab):\n",
        "  print (loaded_model[word])\n",
        "else:\n",
        "  print (\"no vector\")\n",
        "\"\"\""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Token model: but with word2vec (use either FASTTEXT or word2vec but not both)\\nfrom google.colab import drive\\ndrive.mount(\\'/content/drive\\')\\n\\nimport gensim.models\\nword2vec_file=\\'/content/drive/My Drive/Data/fakejobs/gensim_word2vec.mod\\'\\n\\nprint(\\'Loading word vectors...\\')\\nloaded_model = gensim.models.Word2Vec.load(word2vec_file)\\n\\n# Token model: prepare embedding matrix\\nprint(\\'Filling pre-trained embeddings...\\')\\nembedding_matrix = np.zeros((max_num_words, embed_dim))\\nfor word, i in word_index.items():\\n      if (word in loaded_model.wv.vocab):\\n          embedding_matrix[i] = loaded_model[word]\\n          # word\\'s vector not found in embedding index will be all zeros.\\n\\nword=\"salary\"\\nprint(word)\\nif (word in loaded_model.wv.vocab):\\n  print (loaded_model[word])\\nelse:\\n  print (\"no vector\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_g3Yeivx0r7"
      },
      "source": [
        "# Token model: load pre-trained word embeddings into an Embedding layer\n",
        "# We set trainable = True if want to allow the embedding layer to be trained further\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "  max_num_words,\n",
        "  embed_dim,\n",
        "  weights=[embedding_matrix],\n",
        "  input_length=max_length,\n",
        "  trainable=False\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHNBeD6dslhd",
        "outputId": "945e1830-18d8-4cd6-fb48-f5b63991013a"
      },
      "source": [
        "# Char model: Configuration parameters\n",
        "\n",
        "# Assuming that the text has been processed for word tokenization\n",
        "# alphabet=\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
        "alphabet=\"abcdefghijklmnopqrstuvwxyz0123456789\"\n",
        "encoding_size = len(alphabet)\n",
        "char_input_size=1000\n",
        "\n",
        "# Create a dictionary for encoding characters\n",
        "dict = {}  # Maps each character to an integer\n",
        "for idx, char in enumerate(alphabet):\n",
        "  dict[char] = idx + 1\n",
        "\n",
        "print(encoding_size)\n",
        "print (dict)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36\n",
            "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '0': 27, '1': 28, '2': 29, '3': 30, '4': 31, '5': 32, '6': 33, '7': 34, '8': 35, '9': 36}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxU9Y3fL1jeU"
      },
      "source": [
        "# Char model: Utility function(s)\n",
        "\n",
        "# Return one-hot-vector character encoding for string\n",
        "# Memory is allocated outside this routine\n",
        "def str_to_ohv(s, ohv):\n",
        "  max_length = min(len(s), char_input_size)\n",
        "  for i in range(0, max_length):\n",
        "    c = s[i]\n",
        "    if c in dict:\n",
        "      ohv[i, dict[c]-1] = 1\n",
        "  return ohv"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwyr--LJ_luP"
      },
      "source": [
        "# Char model: create train input\n",
        "num_jobs = train_text.shape[0]\n",
        "train_t = np.zeros((num_jobs, char_input_size, encoding_size), dtype=np.int8)\n",
        "i = 0\n",
        "for _, val in train_text.iteritems():\n",
        "  str_to_ohv(val, train_t[i])\n",
        "  i=i+1"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlXCalahJlar"
      },
      "source": [
        "# Char model: create test input\n",
        "num_jobs = test_text.shape[0]\n",
        "test_t = np.zeros((num_jobs, char_input_size, encoding_size), dtype=np.int8)\n",
        "i = 0\n",
        "for _, val in test_text.iteritems():\n",
        "  str_to_ohv(val, test_t[i])\n",
        "  i=i+1"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX_1JKmA6BZy"
      },
      "source": [
        "# The Composite model: Token + Char\n",
        "\n",
        "# Not specificying input dtype as Keras internally assumes float32\n",
        "\n",
        "# Token (word) model\n",
        "token_input = Input(shape=(max_length,), name=\"token_input\")\n",
        "token_embedding = embedding_layer(token_input)\n",
        "# uncomment line below (and comment line above) to switch to inline-only embedding\n",
        "# token_embedding = Embedding(max_num_words, embed_dim, input_length=max_length, name=\"token_embedding\")(token_input)\n",
        "token_conv = Conv1D(64, kernel_size=3, strides=1, padding=\"valid\", activation=\"relu\", name=\"token_conv\")(token_embedding)\n",
        "token_pool = MaxPool1D(pool_size=3, strides=3, name=\"token_pool\")(token_conv)\n",
        "token_drop = Dropout(.5, name=\"token_drop\")(token_pool)\n",
        "\n",
        "# Char model\n",
        "char_input = Input(shape=(char_input_size, encoding_size), name=\"char_input\")\n",
        "char_conv = Conv1D(64, kernel_size=3, strides=1, padding=\"valid\",activation=\"relu\", name=\"char_conv\")(char_input)\n",
        "char_pool = GlobalMaxPool1D(name=\"char_pool\")(char_conv)\n",
        "char_drop = Dropout(.5, name=\"char_drop\")(char_pool)\n",
        "char_repeated = RepeatVector(token_drop.get_shape()[1], name=\"char_repeated\")(char_drop)\n",
        "\n",
        "# Merge\n",
        "merged = Concatenate(axis=2, name=\"concat\")([token_drop, char_repeated])\n",
        "lstm = Bidirectional(LSTM(32, dropout=0.3, recurrent_dropout=0.01, name=\"lstm\"), name=\"bidir\")(merged)\n",
        "output = Dense(1, activation=\"sigmoid\", name=\"output\")(lstm)\n",
        "\n",
        "# define a model with a list of two inputs\n",
        "model = Model(inputs=[token_input, char_input], outputs=output)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUzcT443YL0U",
        "outputId": "1a4472dd-57a4-4efd-faba-c142fb2b4bbc"
      },
      "source": [
        "model.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy', tf.keras.metrics.FalsePositives(), tf.keras.metrics.FalseNegatives()])\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "token_input (InputLayer)        [(None, 250)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "char_input (InputLayer)         [(None, 1000, 36)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 250, 32)      1600000     token_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "char_conv (Conv1D)              (None, 998, 64)      6976        char_input[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "token_conv (Conv1D)             (None, 248, 64)      6208        embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "char_pool (GlobalMaxPooling1D)  (None, 64)           0           char_conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "token_pool (MaxPooling1D)       (None, 82, 64)       0           token_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "char_drop (Dropout)             (None, 64)           0           char_pool[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "token_drop (Dropout)            (None, 82, 64)       0           token_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "char_repeated (RepeatVector)    (None, 82, 64)       0           char_drop[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concat (Concatenate)            (None, 82, 128)      0           token_drop[0][0]                 \n",
            "                                                                 char_repeated[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidir (Bidirectional)           (None, 64)           41216       concat[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            65          bidir[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 1,654,465\n",
            "Trainable params: 54,465\n",
            "Non-trainable params: 1,600,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "KdX53khljBIf",
        "outputId": "ac6087c5-2b77-49f0-846e-9dfd4fff0093"
      },
      "source": [
        "\"\"\"\n",
        "# Uncomment to save image of model architecture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dot_img_file = '/content/drive/My Drive/Results/fj_embedding_composite.png'\n",
        "tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True, show_dtype=True)\n",
        "\"\"\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# Uncomment to save image of model architecture\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n\\ndot_img_file = '/content/drive/My Drive/Results/fj_embedding_composite.png'\\ntf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True, show_dtype=True)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7872Kjn0I6Gc",
        "outputId": "6f7ac70e-49d4-4996-e68b-c18a9e03b5ec"
      },
      "source": [
        "model.fit([train_padded, train_t], train_labels, epochs = 15)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "475/475 [==============================] - 128s 255ms/step - loss: 0.2137 - accuracy: 0.9422 - false_positives: 14.9937 - false_negatives: 369.5651\n",
            "Epoch 2/15\n",
            "475/475 [==============================] - 121s 255ms/step - loss: 0.1845 - accuracy: 0.9520 - false_positives: 0.0000e+00 - false_negatives: 369.0924\n",
            "Epoch 3/15\n",
            "475/475 [==============================] - 122s 256ms/step - loss: 0.1768 - accuracy: 0.9529 - false_positives: 0.0000e+00 - false_negatives: 366.4328\n",
            "Epoch 4/15\n",
            "475/475 [==============================] - 120s 252ms/step - loss: 0.1705 - accuracy: 0.9551 - false_positives: 1.8655 - false_negatives: 349.1996\n",
            "Epoch 5/15\n",
            "475/475 [==============================] - 121s 254ms/step - loss: 0.1756 - accuracy: 0.9501 - false_positives: 7.1071 - false_negatives: 359.5819\n",
            "Epoch 6/15\n",
            "475/475 [==============================] - 120s 254ms/step - loss: 0.1604 - accuracy: 0.9539 - false_positives: 30.2689 - false_negatives: 322.7647\n",
            "Epoch 7/15\n",
            "475/475 [==============================] - 122s 256ms/step - loss: 0.1473 - accuracy: 0.9572 - false_positives: 26.5546 - false_negatives: 297.1261\n",
            "Epoch 8/15\n",
            "475/475 [==============================] - 122s 257ms/step - loss: 0.1257 - accuracy: 0.9606 - false_positives: 44.9265 - false_negatives: 256.3887\n",
            "Epoch 9/15\n",
            "475/475 [==============================] - 121s 254ms/step - loss: 0.1156 - accuracy: 0.9642 - false_positives: 41.8971 - false_negatives: 235.0483\n",
            "Epoch 10/15\n",
            "475/475 [==============================] - 122s 257ms/step - loss: 0.1034 - accuracy: 0.9683 - false_positives: 41.4853 - false_negatives: 206.1071\n",
            "Epoch 11/15\n",
            "475/475 [==============================] - 121s 255ms/step - loss: 0.1031 - accuracy: 0.9684 - false_positives: 37.1134 - false_negatives: 208.9916\n",
            "Epoch 12/15\n",
            "475/475 [==============================] - 121s 255ms/step - loss: 0.1077 - accuracy: 0.9672 - false_positives: 39.3529 - false_negatives: 208.1933\n",
            "Epoch 13/15\n",
            "475/475 [==============================] - 121s 254ms/step - loss: 0.0991 - accuracy: 0.9694 - false_positives: 35.9496 - false_negatives: 200.6008\n",
            "Epoch 14/15\n",
            "475/475 [==============================] - 121s 254ms/step - loss: 0.0989 - accuracy: 0.9680 - false_positives: 40.2983 - false_negatives: 210.8676\n",
            "Epoch 15/15\n",
            "475/475 [==============================] - 120s 254ms/step - loss: 0.0938 - accuracy: 0.9701 - false_positives: 39.2605 - false_negatives: 191.7857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4569dfbf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4B3OYymJPHW"
      },
      "source": [
        "pred_soft = model.predict([test_padded, test_t])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci0Z6vXdJP2p",
        "outputId": "3560b84b-82f3-4f67-8637-e89475429ad1"
      },
      "source": [
        "# pred = np.around(pred_soft, decimals = 0)\n",
        "pred = np.where(pred_soft > 0.15, 1, 0)\n",
        "\n",
        "acc = accuracy_score(pred, test_labels)\n",
        "f1 = f1_score(pred, test_labels)\n",
        "\n",
        "cm = confusion_matrix(test_labels, pred)\n",
        "tn = cm[0][0]\n",
        "fn = cm[1][0]\n",
        "tp = cm[1][1]\n",
        "fp = cm[0][1]\n",
        "\n",
        "print('Accuracy score: {:.4f}'.format(acc), 'F1 score: {:.4f}'.format(f1))\n",
        "print('False Positives: {:.0f}'.format(fp), 'False Negatives: {:.0f}'.format(fn))\n",
        "print('Confusion matrix:\\n', cm)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.9724 F1 score: 0.7132\n",
            "False Positives: 22 False Negatives: 52\n",
            "Confusion matrix:\n",
            " [[2516   22]\n",
            " [  52   92]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm1MoM4U4aQa",
        "outputId": "0f6936c1-40db-4f29-8809-345263c47bbd"
      },
      "source": [
        "auc = roc_auc_score(test_labels, pred_soft)\n",
        "print('AUC score: {:.4f}'.format(auc))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score: 0.9555\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}