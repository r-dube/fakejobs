{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fj_fcnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgZhCQvre/qF1bo0ZTuOgy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-dube/fakejobs/blob/main/fj_fcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFWTUL3GCHsG"
      },
      "source": [
        "# Load the modules used\n",
        "import numpy as np\n",
        "import scipy as sci\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wN7spE3GCrZ"
      },
      "source": [
        "# For reproducible results\n",
        "import random as rn\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = '42'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
        "np.random.seed(42)\n",
        "rn.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrnTamUHDzxI"
      },
      "source": [
        "# Set data_url, the location of the data\n",
        "# Data is not loaded from a local file\n",
        "# data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fj_small.csv\"\n",
        "# data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fj_medium.csv\"\n",
        "data_url=\"https://raw.githubusercontent.com/r-dube/fakejobs/main/data/fake_job_postings.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usYPD_l1Bimz"
      },
      "source": [
        "def fj_load_df_from_url():\n",
        "    \"\"\"\n",
        "    Load dataframe from csv file\n",
        "    Input:\n",
        "        None\n",
        "    Returns:\n",
        "        dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(data_url)\n",
        "\n",
        "    print ('Loaded dataframe shape', df.shape)\n",
        "\n",
        "    counts = fj_label_stats(df)\n",
        "    print ('Not fraudulent', counts[0], 'Fraudulent', counts[1])\n",
        "\n",
        "    print(df.describe())\n",
        "\n",
        "    print ('NAs/NANs in data =>')\n",
        "    print(df.isna().sum())\n",
        "\n",
        "    return df\n",
        "\n",
        "def fj_label_stats(df):\n",
        "    \"\"\"\n",
        "    Very basic label statistics\n",
        "    Input: \n",
        "        Dataframe\n",
        "    Returns:\n",
        "        Number of samples with 0, 1 as the label\n",
        "    \"\"\"\n",
        "    counts = np.bincount(df['fraudulent'])\n",
        "    return counts\n",
        "\n",
        "def fj_txt_only(df):\n",
        "    \"\"\"\n",
        "    Combine all the text fields, discard everything else except for the label\n",
        "    Input: \n",
        "        Dataframe\n",
        "    Returns:\n",
        "        Processed dataframe\n",
        "    \"\"\"\n",
        "    \n",
        "    df.fillna(\" \", inplace = True)\n",
        "\n",
        "    df['text'] = df['title'] + ' ' + df['location'] + ' ' + df['department'] + \\\n",
        "    ' ' + df['company_profile'] + ' ' + df['description'] + ' ' + \\\n",
        "    df['requirements'] + ' ' + df['benefits'] + ' ' + df['employment_type'] + \\\n",
        "    ' ' + df['required_education'] + ' ' + df['industry'] + ' ' + df['function'] \n",
        "\n",
        "    del df['title']\n",
        "    del df['location']\n",
        "    del df['department']\n",
        "    del df['company_profile']\n",
        "    del df['description']\n",
        "    del df['requirements']\n",
        "    del df['benefits']\n",
        "    del df['employment_type']\n",
        "    del df['required_experience']\n",
        "    del df['required_education']\n",
        "    del df['industry']\n",
        "    del df['function']  \n",
        "    \n",
        "    del df['salary_range']\n",
        "    del df['job_id']\n",
        "    del df['telecommuting']\n",
        "    del df['has_company_logo']\n",
        "    del df['has_questions']\n",
        "\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lks9Mm0Tc1l2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104d0921-3e9b-49fd-a3ce-e55f1cdf5282"
      },
      "source": [
        "df = fj_load_df_from_url()\n",
        "df = fj_txt_only(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded dataframe shape (17880, 18)\n",
            "Not fraudulent 17014 Fraudulent 866\n",
            "             job_id  telecommuting  ...  has_questions    fraudulent\n",
            "count  17880.000000   17880.000000  ...   17880.000000  17880.000000\n",
            "mean    8940.500000       0.042897  ...       0.491723      0.048434\n",
            "std     5161.655742       0.202631  ...       0.499945      0.214688\n",
            "min        1.000000       0.000000  ...       0.000000      0.000000\n",
            "25%     4470.750000       0.000000  ...       0.000000      0.000000\n",
            "50%     8940.500000       0.000000  ...       0.000000      0.000000\n",
            "75%    13410.250000       0.000000  ...       1.000000      0.000000\n",
            "max    17880.000000       1.000000  ...       1.000000      1.000000\n",
            "\n",
            "[8 rows x 5 columns]\n",
            "NAs/NANs in data =>\n",
            "job_id                     0\n",
            "title                      0\n",
            "location                 346\n",
            "department             11547\n",
            "salary_range           15012\n",
            "company_profile         3308\n",
            "description                1\n",
            "requirements            2695\n",
            "benefits                7210\n",
            "telecommuting              0\n",
            "has_company_logo           0\n",
            "has_questions              0\n",
            "employment_type         3471\n",
            "required_experience     7050\n",
            "required_education      8105\n",
            "industry                4903\n",
            "function                6455\n",
            "fraudulent                 0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgM-_QC59Rhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29b9132-a81b-47c4-993b-bd5a47db81ac"
      },
      "source": [
        "\"\"\"\n",
        "Use Count Vectorizer to convert text into bag of words\n",
        "\"\"\"\n",
        "train_text, test_text, train_labels , test_labels = train_test_split(df['text'], df['fraudulent'] , test_size = 0.15)\n",
        "\n",
        "cv = CountVectorizer(strip_accents='unicode', lowercase=True, stop_words='english', dtype=np.int8) \n",
        "cv_train_sparse = cv.fit_transform(train_text)\n",
        "cv_train_dense = sci.sparse.csr_matrix.todense(cv_train_sparse)\n",
        "\n",
        "cv_test_sparse = cv.transform(test_text)\n",
        "cv_test_dense = sci.sparse.csr_matrix.todense(cv_test_sparse)\n",
        "\n",
        "print('BOW for cv_train:', cv_train_dense.shape)\n",
        "print('BOW for cv_test:', cv_test_dense.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BOW for cv_train: (15198, 96150)\n",
            "BOW for cv_test: (2682, 96150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqmyjzcr-Mn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "872003f8-7cd9-433d-9b77-9dc17c13a35c"
      },
      "source": [
        "\"\"\"\n",
        "Fully connected NN model with two hidden layers \n",
        "\"\"\"\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 100 , activation = 'relu' , input_dim = cv_train_dense.shape[1]))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(units = 10 , activation = 'relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(units = 1 , activation = 'sigmoid'))\n",
        "model.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy', tf.keras.metrics.FalsePositives(), tf.keras.metrics.FalseNegatives()])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 100)               9615100   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1010      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 9,616,121\n",
            "Trainable params: 9,616,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5yp7QpV-rj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7489001-63fd-4e86-887f-e7e9f69ea4b8"
      },
      "source": [
        "model.fit(cv_train_dense, train_labels, epochs = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "475/475 [==============================] - 33s 69ms/step - loss: 0.0867 - accuracy: 0.9715 - false_positives: 49.0000 - false_negatives: 384.0000\n",
            "Epoch 2/5\n",
            "475/475 [==============================] - 33s 69ms/step - loss: 0.0204 - accuracy: 0.9934 - false_positives: 35.0000 - false_negatives: 65.0000\n",
            "Epoch 3/5\n",
            "475/475 [==============================] - 33s 69ms/step - loss: 0.0055 - accuracy: 0.9982 - false_positives: 10.0000 - false_negatives: 17.0000\n",
            "Epoch 4/5\n",
            "475/475 [==============================] - 33s 69ms/step - loss: 0.0033 - accuracy: 0.9987 - false_positives: 11.0000 - false_negatives: 8.0000\n",
            "Epoch 5/5\n",
            "475/475 [==============================] - 33s 69ms/step - loss: 0.0015 - accuracy: 0.9997 - false_positives: 2.0000 - false_negatives: 2.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7da7df45f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZHOvOrd_shi"
      },
      "source": [
        "pred_soft = model.predict(cv_test_dense)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX18ruW1eliY",
        "outputId": "bb0d1d29-6bc9-4f08-e528-78cf9be728d3"
      },
      "source": [
        "# pred = np.around(pred_soft, decimals = 0)\n",
        "pred = np.where(pred_soft > 0.50, 1, 0)\n",
        "\n",
        "acc = accuracy_score(pred, test_labels)\n",
        "f1 = f1_score(pred, test_labels)\n",
        "\n",
        "cm = confusion_matrix(test_labels, pred)\n",
        "tn = cm[0][0]\n",
        "fn = cm[1][0]\n",
        "tp = cm[1][1]\n",
        "fp = cm[0][1]\n",
        "\n",
        "print('Accuracy score: {:.4f}'.format(acc), 'F1 score: {:.4f}'.format(f1))\n",
        "print('False Positives: {:.0f}'.format(fp), 'False Negatives: {:.0f}'.format(fn))\n",
        "print('Confusion matrix:\\n', cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.9888 F1 score: 0.8864\n",
            "False Positives: 3 False Negatives: 27\n",
            "Confusion matrix:\n",
            " [[2535    3]\n",
            " [  27  117]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "zjBJYGG1e0lI",
        "outputId": "a64734e7-4694-47c1-c916-02929e07649c"
      },
      "source": [
        "\"\"\"\n",
        "# Uncomment to save results on drive to a csv file\n",
        "df_results1 = pd.DataFrame(data=test_labels)\n",
        "df_results1.reset_index(drop=True, inplace=True)\n",
        "df_results2 = pd.DataFrame(data=pred_soft, columns=['fcnn'])\n",
        "df_results = pd.concat([df_results1, df_results2], axis=1)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "results_file='/content/drive/My Drive/Results/fcnn.csv'\n",
        "\n",
        "df_results.to_csv(results_file)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# Uncomment to save results on drive to a csv file\\ndf_results1 = pd.DataFrame(data=test_labels)\\ndf_results1.reset_index(drop=True, inplace=True)\\ndf_results2 = pd.DataFrame(data=pred_soft, columns=['fcnn'])\\ndf_results = pd.concat([df_results1, df_results2], axis=1)\\n\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\nresults_file='/content/drive/My Drive/Results/fcnn.csv'\\n\\ndf_results.to_csv(results_file)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}